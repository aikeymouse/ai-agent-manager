{
  "name": "ollama",
  "description": "AI assistant powered by Ollama",
  "model": "llama3.1:8b",
  "timeout": 120,
  "base_url": "http://host.docker.internal:11434",
  "model_endpoint": "/api/chat",
  "test_endpoint": "/api/show",
  "stream": true,
  "options": {
    "temperature": 0.7,
    "top_p": 0.9,
    "top_k": 40,
    "num_predict": 512,
    "num_ctx": 8192,
    "repeat_penalty": 1.1
  }
}
